{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fbb892",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Plots, StatsPlots, Dates, GLM;\n",
    "using Pipe, StatsPlots, Underscores, Statistics, StatsBase, RollingFunctions;\n",
    "# import data and clean\n",
    "date_of_first_obs = Date(\"2020-07-01\");\n",
    "windowsize = 7; # set window size for aggregating data into windowsize-ly data\n",
    "sub_sample_size = 90;  # 3-months\n",
    "fixN_daily = 100000;  # to get adjusted case numbers\n",
    "fixN_weekly = fixN_daily * 7;\n",
    "fixN_7dd = fixN_daily;\n",
    "Nstar = 5800000;\n",
    "daily = CSV.File(\"pos.csv\") |> DataFrame;\n",
    "n = nrow(daily);\n",
    "delete!(daily, n-1:n);  # last two rows contain some words instead of data, remomve them\n",
    "daily = rename(daily, :Tested => :Nt, :NewPositive => :Ct) |> DataFrame; # rename Nt and Ct\n",
    "daily.Nt .= replace.(daily.Nt, \".\" => \"\");  # There are dots in numbers, i.e. one thousand is written as 1.000, remove dots\n",
    "daily.Nt .= replace.(daily.Nt, \" \" => \"\");\n",
    "daily.Ct .= replace.(daily.Ct, \".\" => \"\");\n",
    "daily.Ct .= replace.(daily.Ct, \" \" => \"\");\n",
    "daily.Nt = parse.(Int, daily.Nt); # change data type from string to integers\n",
    "daily.Ct = parse.(Int, daily.Ct);\n",
    "daily.logNt = log.(daily.Nt); # create log(Nt)\n",
    "daily.logCt = log.(daily.Ct); # create log(Ct)\n",
    "daily.pihat = daily.Ct ./ daily.Nt; # calculate positive ratio\n",
    "daily.pihat = replace!(daily.pihat, NaN => 0); # NaN are created bc some Nt=0, replace NaN with 0\n",
    "daily.Date = Date.(daily.Date, \"yyyy-mm-dd\"); # change data type of Date from string to Date\n",
    "n = nrow(daily);\n",
    "\n",
    "# create daily data set \n",
    "national_daily = @pipe daily |> \n",
    "subset(_, :logCt => c -> .!isinf.(c)) |> \n",
    "select(_, :Date, :logCt, :logNt, :Ct, :Nt, :pihat) |>\n",
    "transform(_, :logCt => (x -> x - lag(x)) => :diff_logCt, \n",
    "             :logNt => (x -> x - lag(x)) => :diff_logNt,\n",
    "             :logNt => (x -> lag(x)) => :lag_logNt) |>\n",
    "dropmissing(_) |>\n",
    "subset(_, :Date => ByRow(D -> D >= date_of_first_obs)); # drop data before 2020-07-01 ;\n",
    "N_daily = nrow(national_daily);\n",
    "\n",
    "# create rolling weekly data set\n",
    "national_weekly = select(daily,\n",
    "    :Date,\n",
    "    :pihat,\n",
    "    :Nt => (v -> runmean(v, windowsize) * windowsize) => :Nt, \n",
    "    :Ct => (v -> runmean(v, windowsize) * windowsize) => :Ct)\n",
    "delete!(national_weekly, 1: (windowsize - 1));\n",
    "national_weekly = @pipe national_weekly |> \n",
    "transform(_, :Nt => (x -> log.(x)) => :logNt,\n",
    "             :Ct => (x -> log.(x)) => :logCt,\n",
    "             :pihat => (x -> log.(x)) => :logPi) |> \n",
    "subset(_, :logCt => c -> .!isinf.(c)) |> \n",
    "transform(_, :logCt => (x -> x - lag(x)) => :diff_logCt, \n",
    "             :logNt => (x -> x - lag(x)) => :diff_logNt,\n",
    "             :logPi => (x -> x - lag(x)) => :diff_logPi,\n",
    "             :logNt => (x -> lag(x)) => :lag_logNt) |> \n",
    "dropmissing(_) |>\n",
    "subset(_, :Date => ByRow(D -> D >= date_of_first_obs)); # drop data before 2020-07-01 ;\n",
    "N_weekly = nrow(national_weekly);\n",
    "\n",
    "# create weekday data set, 7-day difference\n",
    "national_7dd = @pipe daily |> \n",
    "subset(_, :logCt => c -> .!isinf.(c)) |> \n",
    "select(_, :Date, :logCt, :logNt, :Ct, :Nt, :pihat) |>\n",
    "transform(_, :logCt => (x -> x - lag(x, 7)) => :diff_logCt, \n",
    "             :logNt => (x -> x - lag(x, 7)) => :diff_logNt,\n",
    "             :logNt => (x -> lag(x)) => :lag_logNt) |>\n",
    "dropmissing(_) |>\n",
    "subset(_, :Date => ByRow(D -> D >= date_of_first_obs)); # drop data before 2020-07-01 ;\n",
    "N_7dd = nrow(national_7dd);\n",
    "\n",
    "# add sub-sample index to data sets\n",
    "national_daily.subsample = string.(Int.(repeat(1:ceil(N_daily/sub_sample_size), \n",
    "            inner = sub_sample_size)[1:N_daily]));\n",
    "national_weekly.subsample = string.(Int.(repeat(1:ceil(N_weekly/sub_sample_size), \n",
    "            inner = sub_sample_size)[1:N_weekly]));\n",
    "national_7dd.subsample = string.(Int.(repeat(1:ceil(N_7dd/sub_sample_size), \n",
    "            inner = sub_sample_size)[1:N_7dd]));\n",
    "national_weekly.C_tilde = national_weekly.Ct ./ national_weekly.Nt .* Nstar;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c24d9a9",
   "metadata": {},
   "source": [
    "# Old text\n",
    "\n",
    "Define $N_t$ as number of test conducted at day $t$;\n",
    "       $C_t$ as number of observed positive cases at day $t$;\n",
    "       $H_t$ as newly admitted to hospitals at day $t$;\n",
    "       $D_t$ as new death at day $t$.\n",
    "       \n",
    "Also define two unobserved variables, $C_t^*$ as the true number of cases at day $t$ (propotional to the whole population); $S_t^*$ as the severity which is related to the case fatality ratio or the hospitality ratio. \n",
    "\n",
    "Since $C_t^*$ is not affected by $N_t$, but $C_t$ is. To be more specific, when we double number of testing at day $t$, i.e. increase $N_t$ to $2 N_t$, the observed number of postive cases will also increase, although the increment is likely to be less than one $C_t$. So, $C_t$ by itself is not a good estimator for $C_t^*$. Therefore, we want to take into account the variable $N_t$ and construct a more reliable estimate for $C_t^*$.\n",
    "\n",
    "A model proposed,\n",
    "\n",
    "$\\hat{C_t^*} = C_t \\cdot \\left( \\frac{N}{N_t} \\right)^{\\beta}$\n",
    "\n",
    "where $\\beta > 0$. \n",
    "\n",
    "Take log transformation, we have\n",
    "\n",
    "$\\log \\hat{C_t^*}= \\log C_t + \\beta \\cdot \\log \\frac{N}{N_t}$\n",
    "\n",
    "After taking take first difference, we get\n",
    "\n",
    "$\\Delta \\log \\hat{C_t^*} = \\Delta \\log C_t - \\beta \\cdot \\Delta \\log N_t$.\n",
    "\n",
    "Rearrange the model, we can get the OLS estimate of $\\beta$:\n",
    "\n",
    "$\\Delta \\log C_t = \\beta \\cdot \\Delta \\log N_t + \\Delta \\log \\hat{C_t^*}$,\n",
    "\n",
    "$\\hat{\\beta} = \\frac{\\sum \\Delta \\log N_t  \\Delta \\log C_t}{\\sum \\left( \\Delta \\log N_t\\right)^2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1216fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8f716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# different initial values result in different results \n",
    " θ_national_weekly = [0, 1, 0.1, 2, 0];\n",
    "# θ_national_weekly = [0, 0.1, 0.1, 0.9, 0];\n",
    "obj_national_weekly = θ_national_weekly -> logL(θ_national_weekly, national_weekly) \n",
    "res_national_weekly = optimize(obj_national_weekly, θ_national_weekly)\n",
    "Optim.minimizer(res_national_weekly)  # Estimated parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e22b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ScoreBetaHat_national_weekly = ScoreBeta(Optim.minimizer(res_national_weekly), national_weekly);\n",
    "plot(national_weekly.Date, ScoreBetaHat_national_weekly, \n",
    "label = :none,\n",
    "xlabel = \"First day of each rolling week\",\n",
    "ylabel = \"Score \\\\beta_t\")\n",
    "hline!([0], color = :red, label = :none)\n",
    "hline!([1], color = :red, label = :none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9bd852",
   "metadata": {},
   "outputs": [],
   "source": [
    "national_weekly.ScoreBetaHat = ScoreBetaHat_national_weekly;\n",
    "national_weekly.C_tilde_score = exp.(national_weekly.logCt .- \n",
    "national_weekly.ScoreBetaHat .* national_weekly.logNt .+\n",
    "national_weekly.ScoreBetaHat .* nstar)\n",
    "@df national_weekly plot(:Date, :C_tilde_score, yaxis = :log,\n",
    "    label = \"Score Adjusted log(Ct)\", xlabel = \"First day of each rolling week\", ylabel = \"Ct values\", color = :red)\n",
    "@df national_weekly plot!(:Date, :Ct, yaxis = :log,\n",
    "    label = \"Observed log(Ct)\", leg = :topleft, color = :blue)\n",
    "#@df national_weekly plot!(twinx(),:Date, :Nt, yaxis = :log,\n",
    "#    label = \"Observed log(Nt)\", leg = :bottomright, color = :black)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea61b57a",
   "metadata": {},
   "source": [
    "# Old score model\n",
    "Assume normal errors, $\\Delta \\log \\hat{C_t^*} \\sim N(0, \\sigma^2)$. \n",
    "\n",
    "Simplify notation, $y_t = \\Delta \\log C_t$ and $x_t = \\Delta \\log N_t$.\n",
    "\n",
    "The log-likelihood is:\n",
    "\n",
    "$$\\ell(\\beta_t) \\propto - T \\log(\\sigma^2) - \\sum_{t=1}^T \\frac{(y_t - \\beta_t x_t)^2}{\\sigma^2};$$\n",
    "\n",
    "The score is:\n",
    "\n",
    "$$\\frac{\\partial \\ell}{\\partial \\beta_t} = \\frac{1}{\\sigma^2} (y_t - \\beta_t x_t) x_t;$$\n",
    "\n",
    "The hessian is:\n",
    "\n",
    "$$\\frac{\\partial^2 \\ell}{\\partial \\beta_t^2} = - \\frac{1}{\\sigma^2} x_t^2;$$\n",
    "\n",
    "Define\n",
    "$$\\psi(\\beta_t) =\n",
    "\\frac{\\frac{\\partial \\ell}{\\partial \\beta_t}}{\\sqrt{- \\frac{\\partial^2 \\ell}{\\partial \\beta_t^2}}}\n",
    "=\n",
    "\\frac{\\frac{1}{\\sigma^2} (y_t - \\beta_t x_t) x_t}{\\sqrt{\\frac{1}{\\sigma^2} x_t^2}}\n",
    "= \n",
    "\\frac{1}{\\sigma} \\text{sign}(x_t) (y_t - \\beta_t x_t)\n",
    "$$\n",
    "\n",
    "The model is (new version):\n",
    "\n",
    "$$\\beta_{t+1} = \\omega + \\phi \\beta_t + \\alpha \\psi(\\beta_t)\n",
    "=\n",
    "\\omega + \\phi \\beta_t + \\alpha \\frac{\\text{sign}(x_t) (y_t - \\beta_t x_t)}{\\sigma} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d1ef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 100;  # choose sample size to be forecasted\n",
    "function ScoreOutFcast(step, data)\n",
    "    n = nrow(data);\n",
    "    yhat = [];\n",
    "    θ = [0, 1, 1, 0.2, 0.6];\n",
    "    for i in 1:step\n",
    "        ss = n - step + i - 1;\n",
    "        train = data[1:ss, :];\n",
    "        x = train.diff_logNt;\n",
    "        y = train.diff_logCt;\n",
    "        obj = θ -> logL(θ, train);\n",
    "        res = optimize(obj, θ);\n",
    "        θ = Optim.minimizer(res);\n",
    "        β =  recoverBeta(θ, train);\n",
    "        ω = θ[1]; \n",
    "        ϕ = θ[2];\n",
    "        α = θ[3];\n",
    "        σ = θ[4];\n",
    "        βt1 = ω + ϕ * β[ss] + α * sign(x[ss]) * (y[ss] - β[ss] * x[ss]) / σ;\n",
    "        xt1 = data.diff_logNt[ss + 1];\n",
    "        yt1hat = βt1 * xt1;\n",
    "        push!(yhat, yt1hat)\n",
    "    end\n",
    "    return yhat\n",
    "end    \n",
    "ScoreYHat_national_daily = ScoreOutFcast(step, national_daily);\n",
    "ScoreYHat_national_weekly = ScoreOutFcast(step, national_weekly);\n",
    "ScoreYHat_national_7dd = ScoreOutFcast(step, national_7dd);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92515adf",
   "metadata": {},
   "source": [
    "## Section 2.3: Score Out-of-sample Forecast<a class=\"anchor\" id=\"dynamic_out_sample\"></a>\n",
    "\n",
    "The name \"step\" in my code means the sample size of data kept for out-of-sample forecast.\n",
    "\n",
    "If step = 10, I estimate $\\beta$ for 10 times. The first time, I use all data but the last 10 for estimation, and then make one out-of-sample forecast for the last 10th observation; The second time, I use all data but the last 9 for estimation, and only make one step ahead forecast for the last 9th observation; ... Repeat until I have all out-of-sample forecast for the 10 observations.\n",
    "\n",
    "The graph shows observed $\\Delta log C_t$ in blue and predicted in red. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34507c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 10;  # choose sample size to be forecasted\n",
    "function ScoreOutFcast(step, data)\n",
    "    n = nrow(data);\n",
    "    yhat = [];\n",
    "    θstatic0 = [0, 0.1, 1, 0.2, 0.6];\n",
    "    for i in 1:step\n",
    "        ss = n - step + i - 1;\n",
    "        train = data[1:ss, :];\n",
    "        x = train.diff_logNt;\n",
    "        y = train.diff_logCt;\n",
    "        obj = θ -> logL(θ, train);\n",
    "        res = optimize(obj, θstatic0);\n",
    "        θstatic = Optim.minimizer(res);\n",
    "        β =  recoverBeta(θstatic, train);\n",
    "        θ = log.(β ./ (1 .- β));\n",
    "        ω = θstatic[1]; \n",
    "        ϕ = θstatic[2];\n",
    "        α = θstatic[3];\n",
    "        σ = θstatic[4];\n",
    "        score = x[ss] / (σ^2 * exp(θ[ss]) * (1 + exp(-θ[ss]))^2) * (y[ss] - x[ss] / (1 + exp(-θ[ss])));\n",
    "        hessian = x[ss] / (σ^2 * exp(θ[ss]) * (1 + exp(-θ[ss]))^2) *\n",
    "        (2 * y[ss] / (exp(θ[ss]) * (1 + exp(-θ[ss]))) - \n",
    "            y[ss] - \n",
    "            3 * x[ss] / (exp(θ[ss]) * (1 + exp(-θ[ss]))^2) + \n",
    "            x[ss] /  (1 + exp(-θ[ss])));\n",
    "        psi = score / sqrt(abs(hessian));\n",
    "        newθ = ω + ϕ * θ[ss] + α * psi;\n",
    "        βt1 = 1/( 1 + exp(-newθ) );\n",
    "        xt1 = data.diff_logNt[ss + 1];\n",
    "        yt1hat = βt1 * xt1;\n",
    "        push!(yhat, yt1hat)\n",
    "    end\n",
    "    return yhat\n",
    "end    \n",
    "ScoreYHat_national_daily = ScoreOutFcast(step, national_daily);\n",
    "ScoreYHat_national_weekly = ScoreOutFcast(step, national_weekly);\n",
    "ScoreYHat_national_7dd = ScoreOutFcast(step, national_7dd);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c199ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily\n",
    "plot(national_daily.Date[N_daily - step + 1: N_daily], \n",
    "    national_daily.diff_logCt[N_daily - step + 1: N_daily],\n",
    "    color = :blue,\n",
    "    xlabel = \"Date\",\n",
    "    ylabel = \"\\\\Delta log Ct\",\n",
    "    label = \"real\")\n",
    "plot!(national_daily.Date[N_daily - step + 1: N_daily], \n",
    "    ScoreYHat_national_daily,\n",
    "    color = :red,\n",
    "    label = \"fitted\", leg = :topleft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005444d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekly\n",
    "plot(national_weekly.Date[N_weekly - step + 1: N_weekly], \n",
    "    national_weekly.diff_logCt[N_weekly - step + 1: N_weekly],\n",
    "    color = :blue,\n",
    "    xlabel = \"Date\",\n",
    "    ylabel = \"\\\\Delta log Ct\",\n",
    "    label = \"real\")\n",
    "plot!(national_weekly.Date[N_weekly - step + 1: N_weekly], \n",
    "    ScoreYHat_national_weekly,\n",
    "    color = :red,\n",
    "    label = \"fitted\", leg = :bottomleft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed1b04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekday\n",
    "plot(national_7dd.Date[N_7dd - step + 1: N_7dd], \n",
    "    national_7dd.diff_logCt[N_7dd - step + 1: N_7dd],\n",
    "    color = :blue,\n",
    "    xlabel = \"Date\",\n",
    "    ylabel = \"\\\\Delta log Ct\",\n",
    "    label = \"real\")\n",
    "plot!(national_7dd.Date[N_7dd - step + 1: N_7dd], \n",
    "    ScoreYHat_national_7dd,\n",
    "    color = :red,\n",
    "    label = \"fitted\", leg = :bottomleft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a733d15",
   "metadata": {},
   "source": [
    "## Section 3.2: Dynamic Analysis\n",
    "First restrict the intercept and slope in the socre equation to be 0 and 1 respectively.\n",
    "\n",
    "The $\\beta_0$ is also part of the parameters now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a2deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict ω = 0, and ϕ = 1.\n",
    "function Restricted_ScoreBeta(θ, data)\n",
    "    x = data.diff_logNt;\n",
    "    y = data.diff_logCt;\n",
    "    T = nrow(data);\n",
    "    ω = 0;\n",
    "    ϕ = 1;   \n",
    "    α = θ[1]; \n",
    "    σ = θ[2];\n",
    "    β0 = θ[3];\n",
    "    β = [];\n",
    "    push!(β, β0)  \n",
    "    \n",
    "    for i in 1:(T-1)\n",
    "    v = ω + ϕ * β[i] + α * sign(x[i]) * (y[i] - β[i] * x[i]) / σ\n",
    "    push!(β, v)\n",
    "    end\n",
    "    \n",
    "    return β\n",
    "end\n",
    "\n",
    "function Restricted_logL(θ, data)\n",
    "    x = data.diff_logNt;\n",
    "    y = data.diff_logCt;\n",
    "    T = nrow(data);\n",
    "    β = Restricted_ScoreBeta(θ, data);\n",
    "    σ = θ[2];\n",
    "    sum((y .- β .* x).^2)/(σ^2) + T*log(σ^2)   # Note: This is negative logL, not logL.\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9881f3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "muni_daily_score_coef_restricted = DataFrame(City = String[], α = String[], σ = String[], β0 = String[]);\n",
    "muni_daily_score_beta_restricted = DataFrame();\n",
    "θ = [1, 0.2, 0.6];\n",
    "for i in 1 : Int((ncol(muni_daily)-1)/2)\n",
    "    diff_logCt = muni_daily[:, i + 1]\n",
    "    # to match Ct and Nt for the same city ---->\n",
    "    city_name = names(muni_daily)[i + 1]  \n",
    "    diff_logNt = muni_daily[:, string(city_name, \"_1\")]\n",
    "    data = DataFrame(diff_logCt = diff_logCt, diff_logNt = diff_logNt)\n",
    "    obj = θ -> Restricted_logL(θ, data);\n",
    "    res = optimize(obj, θ);\n",
    "    coef_w_name = @pipe Optim.minimizer(res) |> round.(_, digits = 4) |> string.(_) |> append!([city_name],  _);\n",
    "    push!(muni_daily_score_coef_restricted, coef_w_name);\n",
    "    muni_daily_score_beta_restricted[!, city_name] = Restricted_ScoreBeta(Optim.minimizer(res), data);\n",
    "end\n",
    "insertcols!(muni_daily_score_beta_restricted, 1, :Date => muni_daily.Date);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95af5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "muni_weekly_score_coef_restricted = DataFrame(City = String[], α = String[], σ = String[], β0 = String[]);\n",
    "muni_weekly_score_beta_restricted = DataFrame();\n",
    "θ = [1, 0.2, 0.6];\n",
    "for i in 1 : Int((ncol(muni_weekly)-1)/2)\n",
    "    diff_logCt = muni_weekly[:, i + 1]\n",
    "    # to match Ct and Nt for the same city ---->\n",
    "    city_name = names(muni_weekly)[i + 1]  \n",
    "    diff_logNt = muni_weekly[:, string(city_name, \"_1\")]\n",
    "    data = DataFrame(diff_logCt = diff_logCt, diff_logNt = diff_logNt)\n",
    "    obj = θ -> Restricted_logL(θ, data);\n",
    "    res = optimize(obj, θ);\n",
    "    coef_w_name = @pipe Optim.minimizer(res) |> round.(_, digits = 4) |> string.(_) |> append!([city_name],  _);\n",
    "    push!(muni_weekly_score_coef_restricted, coef_w_name);\n",
    "    muni_weekly_score_beta_restricted[!, city_name] = Restricted_ScoreBeta(Optim.minimizer(res), data);\n",
    "end\n",
    "insertcols!(muni_weekly_score_beta_restricted, 1, :Date => muni_weekly.Date);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89adc74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "muni_7dd_score_coef_restricted = DataFrame(City = String[], α = String[], σ = String[], β0 = String[]);\n",
    "muni_7dd_score_beta_restricted = DataFrame();\n",
    "θ = [1, 0.2, 0.6];\n",
    "for i in 1 : Int((ncol(muni_7dd)-1)/2)\n",
    "    diff_logCt = muni_7dd[:, i + 1]\n",
    "    # to match Ct and Nt for the same city ---->\n",
    "    city_name = names(muni_7dd)[i + 1]  \n",
    "    diff_logNt = muni_7dd[:, string(city_name, \"_1\")]\n",
    "    data = DataFrame(diff_logCt = diff_logCt, diff_logNt = diff_logNt)\n",
    "    obj = θ -> Restricted_logL(θ, data);\n",
    "    res = optimize(obj, θ);\n",
    "    coef_w_name = @pipe Optim.minimizer(res) |> round.(_, digits = 4) |> string.(_) |> append!([city_name],  _);\n",
    "    push!(muni_7dd_score_coef_restricted, coef_w_name);\n",
    "    muni_7dd_score_beta_restricted[!, city_name] = Restricted_ScoreBeta(Optim.minimizer(res), data);\n",
    "end\n",
    "insertcols!(muni_7dd_score_beta_restricted, 1, :Date => muni_7dd.Date);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c81e9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abandon code\n",
    "# Aggregate daily data to weekly data (non-overlap, non-rolling window)\n",
    "# df = @pipe daily |> select(_, :Ct, :Nt);\n",
    "# df.week = repeat((1:ceil(Int, n/7)), inner = 7)[1:n];\n",
    "# weekly =  @_ groupby(df, [:week]) |> combine(__, :Ct => sum => :WeekCt, :Nt => sum => :WeekNt);\n",
    "# weekly.logCt = log.(weekly.WeekCt);\n",
    "# weekly.logNt = log.(weekly.WeekNt);\n",
    "# weekly = @pipe transform(weekly, :logCt => (x -> x - lag(x)) => :diff_logCt, \n",
    "#             :logNt => (x -> x - lag(x)) => :diff_logNt) |> \n",
    "# dropmissing(_) |> \n",
    "# subset(_, :diff_logCt => c -> .!isinf.(c), :diff_logCt => c -> .!isnan.(c));"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Julia 1.7.1",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
