{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c24d9a9",
   "metadata": {},
   "source": [
    "# Old text\n",
    "\n",
    "Define $N_t$ as number of test conducted at day $t$;\n",
    "       $C_t$ as number of observed positive cases at day $t$;\n",
    "       $H_t$ as newly admitted to hospitals at day $t$;\n",
    "       $D_t$ as new death at day $t$.\n",
    "       \n",
    "Also define two unobserved variables, $C_t^*$ as the true number of cases at day $t$ (propotional to the whole population); $S_t^*$ as the severity which is related to the case fatality ratio or the hospitality ratio. \n",
    "\n",
    "Since $C_t^*$ is not affected by $N_t$, but $C_t$ is. To be more specific, when we double number of testing at day $t$, i.e. increase $N_t$ to $2 N_t$, the observed number of postive cases will also increase, although the increment is likely to be less than one $C_t$. So, $C_t$ by itself is not a good estimator for $C_t^*$. Therefore, we want to take into account the variable $N_t$ and construct a more reliable estimate for $C_t^*$.\n",
    "\n",
    "A model proposed,\n",
    "\n",
    "$\\hat{C_t^*} = C_t \\cdot \\left( \\frac{N}{N_t} \\right)^{\\beta}$\n",
    "\n",
    "where $\\beta > 0$. \n",
    "\n",
    "Take log transformation, we have\n",
    "\n",
    "$\\log \\hat{C_t^*}= \\log C_t + \\beta \\cdot \\log \\frac{N}{N_t}$\n",
    "\n",
    "After taking take first difference, we get\n",
    "\n",
    "$\\Delta \\log \\hat{C_t^*} = \\Delta \\log C_t - \\beta \\cdot \\Delta \\log N_t$.\n",
    "\n",
    "Rearrange the model, we can get the OLS estimate of $\\beta$:\n",
    "\n",
    "$\\Delta \\log C_t = \\beta \\cdot \\Delta \\log N_t + \\Delta \\log \\hat{C_t^*}$,\n",
    "\n",
    "$\\hat{\\beta} = \\frac{\\sum \\Delta \\log N_t  \\Delta \\log C_t}{\\sum \\left( \\Delta \\log N_t\\right)^2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a5f8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logL (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Optim;\n",
    "function ScoreBeta(θ, data)\n",
    "    x = data.diff_logNt;\n",
    "    y = data.diff_logCt;\n",
    "    T = nrow(data);\n",
    "    ω = θ[1]; \n",
    "    ϕ = θ[2];\n",
    "    α = θ[3]; \n",
    "    σ = θ[4];\n",
    "    β0 = θ[5];\n",
    "    β = [];  \n",
    "    # Checked by CS people, this step is totally fine, wouldn't make any difference to memory or speed.\n",
    "    # During optimazition process, this beta will be cleared after every update.\n",
    "    push!(β, β0)  \n",
    "    \n",
    "    for i in 1:(T-1)\n",
    "        v = ω + ϕ * β[i] + α * sign(x[i]) * (y[i] - β[i] * x[i]) / σ\n",
    "        push!(β, v)\n",
    "    end\n",
    "    \n",
    "    return β\n",
    "end\n",
    "\n",
    "function logL(θ, data)\n",
    "    x = data.diff_logNt;\n",
    "    y = data.diff_logCt;\n",
    "    T = nrow(data);\n",
    "    β = ScoreBeta(θ, data);\n",
    "    σ = θ[4];\n",
    "    sum((y .- β .* x).^2)/(σ^2) + T*log(σ^2)   # Note: This is negative logL, not logL.\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea53ac61",
   "metadata": {},
   "source": [
    "# Old score model\n",
    "Assume normal errors, $\\Delta \\log \\hat{C_t^*} \\sim N(0, \\sigma^2)$. \n",
    "\n",
    "Simplify notation, $y_t = \\Delta \\log C_t$ and $x_t = \\Delta \\log N_t$.\n",
    "\n",
    "The log-likelihood is:\n",
    "\n",
    "$$\\ell(\\beta_t) \\propto - T \\log(\\sigma^2) - \\sum_{t=1}^T \\frac{(y_t - \\beta_t x_t)^2}{\\sigma^2};$$\n",
    "\n",
    "The score is:\n",
    "\n",
    "$$\\frac{\\partial \\ell}{\\partial \\beta_t} = \\frac{1}{\\sigma^2} (y_t - \\beta_t x_t) x_t;$$\n",
    "\n",
    "The hessian is:\n",
    "\n",
    "$$\\frac{\\partial^2 \\ell}{\\partial \\beta_t^2} = - \\frac{1}{\\sigma^2} x_t^2;$$\n",
    "\n",
    "Define\n",
    "$$\\psi(\\beta_t) =\n",
    "\\frac{\\frac{\\partial \\ell}{\\partial \\beta_t}}{\\sqrt{- \\frac{\\partial^2 \\ell}{\\partial \\beta_t^2}}}\n",
    "=\n",
    "\\frac{\\frac{1}{\\sigma^2} (y_t - \\beta_t x_t) x_t}{\\sqrt{\\frac{1}{\\sigma^2} x_t^2}}\n",
    "= \n",
    "\\frac{1}{\\sigma} \\text{sign}(x_t) (y_t - \\beta_t x_t)\n",
    "$$\n",
    "\n",
    "The model is (new version):\n",
    "\n",
    "$$\\beta_{t+1} = \\omega + \\phi \\beta_t + \\alpha \\psi(\\beta_t)\n",
    "=\n",
    "\\omega + \\phi \\beta_t + \\alpha \\frac{\\text{sign}(x_t) (y_t - \\beta_t x_t)}{\\sigma} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c81e9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abandon code\n",
    "# Aggregate daily data to weekly data (non-overlap, non-rolling window)\n",
    "# df = @pipe daily |> select(_, :Ct, :Nt);\n",
    "# df.week = repeat((1:ceil(Int, n/7)), inner = 7)[1:n];\n",
    "# weekly =  @_ groupby(df, [:week]) |> combine(__, :Ct => sum => :WeekCt, :Nt => sum => :WeekNt);\n",
    "# weekly.logCt = log.(weekly.WeekCt);\n",
    "# weekly.logNt = log.(weekly.WeekNt);\n",
    "# weekly = @pipe transform(weekly, :logCt => (x -> x - lag(x)) => :diff_logCt, \n",
    "#             :logNt => (x -> x - lag(x)) => :diff_logNt) |> \n",
    "# dropmissing(_) |> \n",
    "# subset(_, :diff_logCt => c -> .!isinf.(c), :diff_logCt => c -> .!isnan.(c));"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Julia 1.7.1",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
